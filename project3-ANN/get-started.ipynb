{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from hyperopt import Trials, STATUS_OK, tpe, hp, fmin \n",
    "from mlflow.models import infer_signature\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3134, 11), (3134, 11), (784, 11), (784, 11))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep = \";\"\n",
    ")\n",
    "train, test = train_test_split(\n",
    "    data,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=True\n",
    ")\n",
    "x_train = train.drop(\n",
    "    \"quality\", axis=1\n",
    ").values\n",
    "y_train = train[[\"quality\"]].values.ravel()\n",
    "\n",
    "x_val = test.drop(\n",
    "    \"quality\", axis=1\n",
    ").values\n",
    "y_val = test[[\"quality\"]].values.ravel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, x_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/760068880112179797', creation_time=1743573525892, experiment_id='760068880112179797', last_update_time=1743573525892, lifecycle_stage='active', name='ANN-Project2', tags={}>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature = infer_signature(\n",
    "    x_train, y_train\n",
    ")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"ANN-Project2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(params, epochs, x_train, y_train, x_test, y_test, x_val, y_val):\n",
    "    \n",
    "    mean = np.mean(x_train, axis = 0)\n",
    "    var = np.var(x_train, axis = 0)\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input([x_train.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean, variance=var),\n",
    "            keras.layers.Dense(128, activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "        loss=keras.losses.MeanSquaredError(),\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_val, y_val),\n",
    "            batch_size=32\n",
    "        )\n",
    "        eval = model.evaluate(x_test, y_test, batch_size=32)\n",
    "        rmse = eval[1]\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_param(\"learning_rate\", params[\"learning_rate\"])\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"batch_size\", 32)\n",
    "        mlflow.log_param(\"optimizer\", \"Adam\")\n",
    "        mlflow.log_param(\"loss\", \"MSE\")\n",
    "        mlflow.log_param(\"metrics\", \"RMSE\")\n",
    "        mlflow.tensorflow.log_model(model, \"model\")\n",
    "    return {\n",
    "        \"loss\":rmse,\n",
    "        \"status\":STATUS_OK,\n",
    "        \"model\":model\n",
    "    }\n",
    "\n",
    "def objective(params):\n",
    "    result = train(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        x_train=x_train,\n",
    "        y_train=y_train,\n",
    "        x_test=x_test,\n",
    "        y_test=y_test,\n",
    "        x_val=x_val,    \n",
    "        y_val=y_val,\n",
    "    )\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m51s\u001b[0m 526ms/step - loss: 1978.7511 - root_mean_squared_error: 44.4832\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1847.1556 - root_mean_squared_error: 42.9635 - val_loss: 196.6388 - val_root_mean_squared_error: 14.0228\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1741.2993 - root_mean_squared_error: 41.7289\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step - loss: 1678.6101 - root_mean_squared_error: 40.9704 - val_loss: 195.4256 - val_root_mean_squared_error: 13.9795\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - loss: 1394.2781 - root_mean_squared_error: 37.3400\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - loss: 1664.1766 - root_mean_squared_error: 40.7916 - val_loss: 193.0283 - val_root_mean_squared_error: 13.8935\n",
      "\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 1805.5391 - root_mean_squared_error: 42.4916\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 1769.7277 - root_mean_squared_error: 42.0663\n",
      "\n",
      "  0%|          | 0/4 [00:01<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 11:32:19 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\n",
      "\u001b[31m2025/04/02 11:32:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run kindly-shrimp-968 at: http://127.0.0.1:5000/#/experiments/760068880112179797/runs/21d167e8a3a64b459dfce3741e5bcbaa\n",
      "\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/760068880112179797\n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - loss: 1956.7151 - root_mean_squared_error: 44.2348\n",
      "\u001b[1m47/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1973.5928 - root_mean_squared_error: 44.4245   \n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1964.1158 - root_mean_squared_error: 44.3175 - val_loss: 25.3514 - val_root_mean_squared_error: 5.0350\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 1891.7937 - root_mean_squared_error: 43.4948\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - loss: 1747.1650 - root_mean_squared_error: 41.7960 - val_loss: 180.9126 - val_root_mean_squared_error: 13.4504\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1588.4073 - root_mean_squared_error: 39.8548\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - loss: 1691.0858 - root_mean_squared_error: 41.1224 - val_loss: 191.7623 - val_root_mean_squared_error: 13.8478\n",
      "\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1823.6484 - root_mean_squared_error: 42.7042\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - loss: 1784.6799 - root_mean_squared_error: 42.2437\n",
      "\n",
      " 25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:08<00:21,  7.25s/trial, best loss: 41.544273376464844]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 11:32:26 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\n",
      "\u001b[31m2025/04/02 11:32:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run ambitious-stoat-548 at: http://127.0.0.1:5000/#/experiments/760068880112179797/runs/0a6bdd6ff1ae46259d5b1b3d4edf2a4b\n",
      "\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/760068880112179797  \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m23s\u001b[0m 245ms/step - loss: 2106.5317 - root_mean_squared_error: 45.8970\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2073.7346 - root_mean_squared_error: 45.5372 - val_loss: 36.5384 - val_root_mean_squared_error: 6.0447\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 1892.8929 - root_mean_squared_error: 43.5074\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 2037.2317 - root_mean_squared_error: 45.1330 - val_loss: 33.8811 - val_root_mean_squared_error: 5.8207\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2103.8638 - root_mean_squared_error: 45.8679\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - loss: 1993.1704 - root_mean_squared_error: 44.6422 - val_loss: 31.3614 - val_root_mean_squared_error: 5.6001\n",
      "\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 2180.3794 - root_mean_squared_error: 46.6945\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - loss: 2136.1704 - root_mean_squared_error: 46.2167\n",
      "\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:14<00:13,  6.77s/trial, best loss: 41.544273376464844]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 11:32:32 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\n",
      "\u001b[31m2025/04/02 11:32:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run debonair-bass-855 at: http://127.0.0.1:5000/#/experiments/760068880112179797/runs/3d153dbeaf224f97ba3ff3d813a1e2c7\n",
      "\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/760068880112179797  \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - loss: 1915.9988 - root_mean_squared_error: 43.7721\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1997.4395 - root_mean_squared_error: 44.6887 - val_loss: 14.6284 - val_root_mean_squared_error: 3.8247\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2121.2156 - root_mean_squared_error: 46.0567\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - loss: 1936.0419 - root_mean_squared_error: 43.9966 - val_loss: 16.0050 - val_root_mean_squared_error: 4.0006\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/98\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1923.8381 - root_mean_squared_error: 43.8616\n",
      "\u001b[1m98/98\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - loss: 1823.6055 - root_mean_squared_error: 42.6982 - val_loss: 58.6530 - val_root_mean_squared_error: 7.6585\n",
      "\n",
      "\u001b[1m 1/25\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 1885.7565 - root_mean_squared_error: 43.4253\n",
      "\u001b[1m25/25\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - loss: 1849.4409 - root_mean_squared_error: 43.0035\n",
      "\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:20<00:06,  6.33s/trial, best loss: 41.544273376464844]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/02 11:32:38 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "\n",
      "\u001b[31m2025/04/02 11:32:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run intelligent-stag-663 at: http://127.0.0.1:5000/#/experiments/760068880112179797/runs/f65f251964e2475e91d4de2177a90d00\n",
      "\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/760068880112179797  \n",
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:25<00:00,  6.33s/trial, best loss: 41.544273376464844]\n",
      "ğŸƒ View run legendary-ape-757 at: http://127.0.0.1:5000/#/experiments/760068880112179797/runs/0b71930124e4440a9f17593977719c19\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/760068880112179797\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    \"learning_rate\": hp.loguniform(\"learning_rate\", low=np.log(1e-5), high=np.log(1e-1)),\n",
    "}\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    trails = Trials()\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials=trails\n",
    "    )\n",
    "    best_run = sorted(\n",
    "        trails.results,\n",
    "        key = lambda x: x[\"loss\"]\n",
    "    )[0]\n",
    "    \n",
    "    mlflow.log_params(best)\n",
    "    mlflow.tensorflow.log_model(\n",
    "        best_run[\"model\"], \"model\", signature=signature\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
